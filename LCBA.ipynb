{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1113d9c8",
   "metadata": {},
   "source": [
    "# Light-contact boxing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cccbdea",
   "metadata": {},
   "source": [
    "# Import\n",
    "\n",
    "Le code effectue l'importation de différentes bibliothèques et modules Python nécessaires à l'analyse de données et à la visualisation. Voici une description synthétique de chaque import :\n",
    "\n",
    "- `pandas as pd` : Importe la bibliothèque Pandas pour la manipulation et l'analyse de données tabulaires.\n",
    "- `numpy as np` : Importe la bibliothèque NumPy pour les calculs numériques efficaces.\n",
    "- `matplotlib.pyplot as plt` : Importe la bibliothèque Matplotlib pour la création de visualisations graphiques, en utilisant le module `pyplot`.\n",
    "- `plotly.graph_objects as go` : Importe la bibliothèque Plotly pour les visualisations interactives et dynamiques, en utilisant le module `graph_objects`.\n",
    "- `matplotlib.dates as mdates` : Importe le module `dates` de Matplotlib pour travailler avec des données de type date et heure dans les tracés.\n",
    "- `scipy.stats as stats` : Importe le module `stats` de SciPy pour les fonctions statistiques et les distributions de probabilité.\n",
    "- `sklearn.ensemble import IsolationForest` : Importe la classe `IsolationForest` de scikit-learn pour détecter les anomalies à l'aide de l'algorithme de la forêt isolante.\n",
    "- `sklearn.cluster import DBSCAN` : Importe la classe `DBSCAN` de scikit-learn pour effectuer le clustering basé sur la densité des données.\n",
    "- `sklearn import metrics` : Importe le module `metrics` de scikit-learn pour les métriques d'évaluation des modèles d'apprentissage automatique.\n",
    "- `sklearn.preprocessing import StandardScaler` : Importe la classe `StandardScaler` de scikit-learn pour la normalisation des données.\n",
    "- `fastdtw` : Importe la fonction `fastdtw` de la bibliothèque FastDTW pour calculer la distance DTW entre deux séries temporelles.\n",
    "- `scipy.spatial.distance import euclidean` : Importe la fonction `euclidean` du module `distance` de SciPy pour calculer la distance euclidienne entre deux vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2cce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.dates as mdates\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac59229",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f32eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('LCBA_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75163c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38783 entries, 0 to 38782\n",
      "Data columns (total 37 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   score_id                  38783 non-null  int64  \n",
      " 1   red_penalty               38783 non-null  int64  \n",
      " 2   red_point                 38783 non-null  int64  \n",
      " 3   blue_penalty              38783 non-null  int64  \n",
      " 4   blue_point                38783 non-null  int64  \n",
      " 5   date_create               38783 non-null  object \n",
      " 6   date_change               38783 non-null  object \n",
      " 7   judge_id                  38783 non-null  int64  \n",
      " 8   match_id                  38783 non-null  int64  \n",
      " 9   date_create_app           36786 non-null  object \n",
      " 10  uuid                      36786 non-null  object \n",
      " 11  judge_club_id             38783 non-null  int64  \n",
      " 12  match_id.1                38783 non-null  int64  \n",
      " 13  PalmaresDate              38783 non-null  object \n",
      " 14  winner                    38745 non-null  object \n",
      " 15  PalmaresRedCountRanking   38783 non-null  bool   \n",
      " 16  PalmaresBlueCountRanking  38783 non-null  bool   \n",
      " 17  PalmaresRound             1157 non-null   float64\n",
      " 18  PalmaresFightNr           38783 non-null  int64  \n",
      " 19  PalmaresFinal             38783 non-null  bool   \n",
      " 20  PalmaresDeleted           38783 non-null  bool   \n",
      " 21  PalmaresBlueClubID        38783 non-null  int64  \n",
      " 22  PalmaresBlueMemberID      38783 non-null  int64  \n",
      " 23  PalmaresRedClubID         38783 non-null  int64  \n",
      " 24  PalmaresRedMemberID       38783 non-null  int64  \n",
      " 25  PalmaresResultID          38745 non-null  float64\n",
      " 26  PalmaresTournamentID      38783 non-null  int64  \n",
      " 27  PalmaresTrophyRuleID      27484 non-null  float64\n",
      " 28  PalmaresPublished         38783 non-null  bool   \n",
      " 29  PalmaresRealEndTime       38701 non-null  object \n",
      " 30  PalmaresRealStartTime     38783 non-null  object \n",
      " 31  PalmaresRingID            38676 non-null  float64\n",
      " 32  blue_injured              38783 non-null  bool   \n",
      " 33  open_time                 38783 non-null  object \n",
      " 34  red_injured               38783 non-null  bool   \n",
      " 35  blue_height               38783 non-null  int64  \n",
      " 36  red_height                38783 non-null  int64  \n",
      "dtypes: bool(7), float64(4), int64(17), object(9)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e35416e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de match_id distincts : 813\n"
     ]
    }
   ],
   "source": [
    "num_distinct_match_ids = data['match_id'].nunique()\n",
    "print(\"Nombre de match_id distincts :\", num_distinct_match_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e94cb0",
   "metadata": {},
   "source": [
    "#### Description détaillés des colonnes qui seront les plus utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b22f648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38783.000000\n",
       "mean         0.456102\n",
       "std          0.561632\n",
       "min         -3.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          1.000000\n",
       "max          3.000000\n",
       "Name: red_point, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.red_point.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab53288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38783.000000\n",
       "mean         0.098858\n",
       "std          0.359887\n",
       "min         -3.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          3.000000\n",
       "Name: red_penalty, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.red_penalty.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5cd89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38783.000000\n",
       "mean         0.457288\n",
       "std          0.556790\n",
       "min         -3.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          1.000000\n",
       "max          3.000000\n",
       "Name: blue_point, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.blue_point.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73379b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38783.000000\n",
       "mean         0.106825\n",
       "std          0.380282\n",
       "min         -3.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          3.000000\n",
       "Name: blue_penalty, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.blue_penalty.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c1c55eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                          36786\n",
       "unique                         36782\n",
       "top       2022-06-18 12:36:59.029+00\n",
       "freq                               2\n",
       "Name: date_create_app, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.date_create_app.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e9d5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     38783.000000\n",
       "mean     113041.017688\n",
       "std        3890.411609\n",
       "min      100124.000000\n",
       "25%      113341.000000\n",
       "50%      114926.000000\n",
       "75%      114928.000000\n",
       "max      115285.000000\n",
       "Name: judge_id, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.judge_id.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1e58e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38783.000000\n",
       "mean     21845.530645\n",
       "std        401.528301\n",
       "min      21089.000000\n",
       "25%      21487.000000\n",
       "50%      21923.000000\n",
       "75%      22202.000000\n",
       "max      22515.000000\n",
       "Name: match_id, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.match_id.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ccae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     38745\n",
       "unique        4\n",
       "top        blue\n",
       "freq      17296\n",
       "Name: winner, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.winner.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9ae1cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38783.000000\n",
       "mean       109.258979\n",
       "std         42.095726\n",
       "min          4.000000\n",
       "25%        101.000000\n",
       "50%        118.000000\n",
       "75%        138.000000\n",
       "max        213.000000\n",
       "Name: judge_club_id, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.judge_club_id.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd8b5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38783.000000\n",
       "mean        93.819354\n",
       "std         58.227887\n",
       "min          4.000000\n",
       "25%         47.000000\n",
       "50%        101.000000\n",
       "75%        154.000000\n",
       "max        213.000000\n",
       "Name: PalmaresBlueClubID, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.PalmaresBlueClubID.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d4e104d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38783.000000\n",
       "mean       100.609004\n",
       "std         58.236669\n",
       "min          4.000000\n",
       "25%         67.000000\n",
       "50%        101.000000\n",
       "75%        155.000000\n",
       "max        213.000000\n",
       "Name: PalmaresRedClubID, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.PalmaresRedClubID.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22174310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de match_ids avec 'lost' : 1\n",
      "Nombre de match_ids avec 'draw' : 101\n",
      "Nombre de match_ids avec 'red' : 350\n",
      "Nombre de match_ids avec 'blue' : 360\n"
     ]
    }
   ],
   "source": [
    "count_lost_matches = data[data['winner'] == 'lost']['match_id'].nunique()\n",
    "\n",
    "count_draw_matches = data[data['winner'] == 'draw']['match_id'].nunique()\n",
    "\n",
    "count_red_matches = data[data['winner'] == 'red']['match_id'].nunique()\n",
    "\n",
    "count_blue_matches = data[data['winner'] == 'blue']['match_id'].nunique()\n",
    "\n",
    "\n",
    "print(\"Nombre de match_ids avec 'lost' :\", count_lost_matches)\n",
    "print(\"Nombre de match_ids avec 'draw' :\", count_draw_matches)\n",
    "print(\"Nombre de match_ids avec 'red' :\", count_red_matches)\n",
    "print(\"Nombre de match_ids avec 'blue' :\", count_blue_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ee89fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de match_ids avec 3 judge_ids : 523\n",
      "Nombre de match_ids avec 2 judge_ids : 254\n",
      "Nombre de match_ids avec 1 judge_id : 36\n"
     ]
    }
   ],
   "source": [
    "# Définir la liste des match_ids\n",
    "match_ids = data['match_id'].unique()\n",
    "\n",
    "# Compteurs pour les match_ids\n",
    "count_match_ids_with_3_judge_ids = 0\n",
    "count_match_ids_with_2_judge_ids = 0\n",
    "count_match_ids_with_1_judge_id = 0\n",
    "\n",
    "# Parcourir tous les match_ids\n",
    "for match_id in match_ids:\n",
    "    # Sélectionner les lignes correspondant au match_id actuel\n",
    "    match_data = data[data['match_id'] == match_id].copy()\n",
    "\n",
    "    # Obtenir les judge_ids distincts pour le match_id actuel\n",
    "    unique_judge_ids = match_data['judge_id'].unique()\n",
    "\n",
    "    # Vérifier le nombre d'identifiants de juge distincts\n",
    "    if len(unique_judge_ids) == 3:\n",
    "        count_match_ids_with_3_judge_ids += 1\n",
    "    elif len(unique_judge_ids) == 2:\n",
    "        count_match_ids_with_2_judge_ids += 1\n",
    "    elif len(unique_judge_ids) == 1:\n",
    "        count_match_ids_with_1_judge_id += 1\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Nombre de match_ids avec 3 judge_ids :\", count_match_ids_with_3_judge_ids)\n",
    "print(\"Nombre de match_ids avec 2 judge_ids :\", count_match_ids_with_2_judge_ids)\n",
    "print(\"Nombre de match_ids avec 1 judge_id :\", count_match_ids_with_1_judge_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8013ee6",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6b503",
   "metadata": {},
   "source": [
    "### Conversion date\n",
    "\n",
    "Ce code convertit les colonnes spécifiées dans la liste `cols_to_convert` en objets de type datetime en utilisant la fonction `pd.to_datetime` de la bibliothèque Pandas. Les nouvelles valeurs converties sont ensuite assignées aux colonnes correspondantes dans le DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "929a97d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_convert = ['date_create', 'date_change','date_create_app','PalmaresDate','PalmaresRealEndTime','PalmaresRealStartTime','open_time']\n",
    "data[cols_to_convert] = data[cols_to_convert].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09a109",
   "metadata": {},
   "source": [
    "### Suppresion des colonnes nulles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714ece2",
   "metadata": {},
   "source": [
    "Ce code identifie et affiche les lignes du DataFrame `data` qui ont une valeur manquante dans la colonne 'date_create_app', puis supprime ces lignes du DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc87ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       score_id  red_point  blue_point  judge_id date_create_app\n",
      "0             1          0           0    114816             NaT\n",
      "1             2          0           0    114822             NaT\n",
      "2             3          0           0    114824             NaT\n",
      "3             4          0           0    114826             NaT\n",
      "4             5          0           0    114813             NaT\n",
      "...         ...        ...         ...       ...             ...\n",
      "38639     38813          0           0    114927             NaT\n",
      "38640     38814          0           0    114926             NaT\n",
      "38711     38885          0           0    114927             NaT\n",
      "38712     38886          0           0    114926             NaT\n",
      "38713     38887          0           0    115226             NaT\n",
      "\n",
      "[1997 rows x 5 columns]\n",
      "Nombre de lignes supprimées : 1997\n"
     ]
    }
   ],
   "source": [
    "null_rows = data[data['date_create_app'].isnull()]\n",
    "\n",
    "cols_to_display = ['score_id', 'red_point', 'blue_point', 'judge_id', 'date_create_app']\n",
    "print(null_rows[cols_to_display])\n",
    "\n",
    "data = data.dropna(subset=['date_create_app'])\n",
    "\n",
    "num_rows_deleted = len(null_rows)\n",
    "print(\"Nombre de lignes supprimées :\", num_rows_deleted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80580ca",
   "metadata": {},
   "source": [
    "### Correction user\n",
    "Ce code compte le nombre de lignes dans le DataFrame 'data' où les colonnes 'red_point' et 'blue_point' ont des valeurs négatives, puis affiche ces nombres. Ceci permet d'avoir une idée du nombre de lignes correspondant à une correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9e80b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes avec red_point corrigés : 352\n",
      "Nombre de lignes avec blue_point corrigés : 415\n"
     ]
    }
   ],
   "source": [
    "num_negative_red_points = sum((data['red_point'] < 0) & (data['blue_penalty'] == 0))\n",
    "num_negative_blue_points = sum((data['blue_point'] < 0) & (data['red_penalty'] == 0))\n",
    "\n",
    "print(\"Nombre de lignes avec red_point corrigés :\", num_negative_red_points)\n",
    "print(\"Nombre de lignes avec blue_point corrigés :\", num_negative_blue_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e723c02e",
   "metadata": {},
   "source": [
    "Ce code permet de supprimer les lignes qui ont une valeur négative dans les colonnes 'red_point' ou 'blue_point' tout en conservant la ligne la plus proche en termes de temps (utilisant la colonne 'date_create_app') pour chaque combinaison de 'judge_id' et 'match_id'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de96d776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes supprimées : 1534\n"
     ]
    }
   ],
   "source": [
    "# Convertir la colonne 'date_create_app' en datetime\n",
    "data['date_create_app'] = pd.to_datetime(data['date_create_app'])\n",
    "\n",
    "num_deleted_rows = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    red_point = row['red_point'] \n",
    "    blue_point = row['blue_point']\n",
    "    red_penalty = row['red_penalty']\n",
    "    blue_penalty = row['blue_penalty']\n",
    "    judge_id = row['judge_id']\n",
    "    match_id = row['match_id']\n",
    "    current_timestamp = row['date_create_app']\n",
    "\n",
    "    # Vérifier si une seule colonne contient une valeur négative\n",
    "    if ((red_point < 0) ^ (blue_point < 0)) and (red_penalty == 0) and (blue_penalty == 0):\n",
    "        \n",
    "        # Rechercher les lignes avec le même judge_id et match_id\n",
    "        same_judge_id_rows = data[(data['judge_id'] == judge_id) & (data['match_id'] == match_id)]\n",
    "        \n",
    "        if len(same_judge_id_rows) > 1:\n",
    "            # Calculer la distance\n",
    "            time_diff = abs(same_judge_id_rows['date_create_app'] - current_timestamp)\n",
    "\n",
    "            # Trouver l'index de la ligne la plus proche\n",
    "            closest_index = time_diff[time_diff.index != index].idxmin()\n",
    "\n",
    "            # Supprimer la ligne la plus proche (si elle existe)\n",
    "            data = data.drop(closest_index, errors='ignore')\n",
    "            num_deleted_rows += 1\n",
    "\n",
    "        # Supprimer la ligne actuelle\n",
    "        data = data.drop(index, errors='ignore')\n",
    "        num_deleted_rows += 1\n",
    "\n",
    "print(\"Nombre de lignes supprimées :\", num_deleted_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef27510",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81b4e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     match_id  red_point  blue_point\n",
      "0       21089         29          27\n",
      "1       21092         12          25\n",
      "2       21093         21          32\n",
      "3       21095         31          37\n",
      "4       21096         35          33\n",
      "..        ...        ...         ...\n",
      "803     22511         11          26\n",
      "804     22512         10          10\n",
      "805     22513         40          26\n",
      "806     22514         34          35\n",
      "807     22515         25          25\n",
      "\n",
      "[808 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "total_points = data.groupby(\"match_id\")[[\"red_point\", \"blue_point\"]].sum().reset_index()\n",
    "\n",
    "print(total_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b8e8f",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf4c65",
   "metadata": {},
   "source": [
    "### Détection des rounds\n",
    "\n",
    "Ce code détecte les rounds dans les données de matchs en effectuant le clustering des dates de création à l'aide de l'algorithme DBSCAN. Il attribue ensuite un numéro de round à chaque match en fonction du résultat du clustering. Les outliers sont également identifiés et stockés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4849232",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       score_id  match_id                  date_create_app  outlier round\n",
      "5             6     21089 2021-06-26 11:14:51.610000+00:00    False     1\n",
      "6             7     21089 2021-06-26 11:14:48.802000+00:00    False     1\n",
      "7             8     21089 2021-06-26 11:14:53.035000+00:00    False     1\n",
      "8             9     21089 2021-06-26 11:14:53.541000+00:00    False     1\n",
      "10           11     21089 2021-06-26 11:14:58.645000+00:00    False     1\n",
      "...         ...       ...                              ...      ...   ...\n",
      "38778     38952     22514 2023-04-15 14:18:52.200000+00:00    False     3\n",
      "38779     38953     22514 2023-04-15 14:18:51.485000+00:00    False     3\n",
      "38780     38954     22514 2023-04-15 14:18:56.330000+00:00    False     3\n",
      "38781     38955     22514 2023-04-15 14:18:56.889000+00:00    False     3\n",
      "38782     38956     22514 2023-04-15 14:19:01.423000+00:00    False     3\n",
      "\n",
      "[26542 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filtrer le dataset pour ne conserver que les lignes avec 3 judge_id par match_id\n",
    "data = data.groupby('match_id').filter(lambda x: x['judge_id'].nunique() == 3)\n",
    "\n",
    "# Définir la liste des match_ids\n",
    "match_ids = data['match_id'].unique()\n",
    "\n",
    "# Créer une nouvelle colonne pour stocker les valeurs de round\n",
    "data['round'] = None\n",
    "\n",
    "# Définir la liste des outliers\n",
    "outliers = []\n",
    "\n",
    "# Parcourir tous les match_ids\n",
    "for match_id in match_ids:\n",
    "    \n",
    "    # Sélectionner les lignes correspondant au match_id actuel\n",
    "    match_data = data[data['match_id'] == match_id].copy()\n",
    "\n",
    "    # Trier les valeurs par ordre chronologique dans la colonne \"date_create_app\"\n",
    "    match_data.sort_values(by='date_create_app', inplace=True)\n",
    "\n",
    "    # Conversion de la colonne \"date_create_app\" en valeurs numériques\n",
    "    match_data['timestamp'] = match_data['date_create_app'].apply(lambda x: pd.to_datetime(x).timestamp())\n",
    "\n",
    "    # Sélection des colonnes à utiliser pour le clustering\n",
    "    features = match_data[['timestamp']]\n",
    "\n",
    "    # Normalisation des caractéristiques\n",
    "    scaler = StandardScaler()\n",
    "    normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Application de DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.4, min_samples=5)\n",
    "    labels = dbscan.fit_predict(normalized_features)\n",
    "\n",
    "    # Mise à jour de la colonne \n",
    "    match_data['round'] = labels + 1\n",
    "    data.loc[data['match_id'] == match_id, 'round'] = match_data['round'].values\n",
    "\n",
    "    # Stocker les indices des outliers dans le tableau outliers\n",
    "    match_outliers = match_data[labels == -1]\n",
    "    outliers.extend(match_outliers.index.tolist())\n",
    "\n",
    "# Ajouter une colonne \"outlier\" avec la valeur \"True\" pour les lignes détectées comme outliers et les autres à \"False\"\n",
    "data['outlier'] = False\n",
    "data.loc[outliers, 'outlier'] = True\n",
    "\n",
    "print(data[['score_id', 'match_id', 'date_create_app', 'outlier','round']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7e040d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de match_ids sans 3 rounds : 89\n",
      "Nombre de match_ids avec 3 rounds : 430\n"
     ]
    }
   ],
   "source": [
    "match_ids = data['match_id'].unique()\n",
    "\n",
    "count_match_ids_without_3_rounds = 0\n",
    "count_match_ids_with_3_rounds = 0\n",
    "\n",
    "for match_id in match_ids:\n",
    "    match_data = data[data['match_id'] == match_id].copy()\n",
    "\n",
    "    unique_rounds = match_data['round'].unique()\n",
    "\n",
    "    if len(unique_rounds) != 3:\n",
    "        count_match_ids_without_3_rounds += 1\n",
    "\n",
    "    if len(unique_rounds) == 3:\n",
    "        count_match_ids_with_3_rounds += 1\n",
    "\n",
    "print(\"Nombre de match_ids sans 3 rounds :\", count_match_ids_without_3_rounds)\n",
    "\n",
    "print(\"Nombre de match_ids avec 3 rounds :\", count_match_ids_with_3_rounds)\n",
    "\n",
    "match_ids = data['match_id'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94bb7f0",
   "metadata": {},
   "source": [
    "### Détection des phases\n",
    "\n",
    "Ce code détecte les phases des matchs en utilisant le clustering des dates de création pour chaque round. Il attribue des clusters distincts aux phases et met à jour la colonne 'phase'. Une phase est défini pour permettre un meilleur découpage du round pour le calcul des échanges plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98ce538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       score_id  match_id                  date_create_app round phase\n",
      "5             6     21089 2021-06-26 11:14:51.610000+00:00     1     1\n",
      "6             7     21089 2021-06-26 11:14:48.802000+00:00     1     1\n",
      "7             8     21089 2021-06-26 11:14:53.035000+00:00     1     1\n",
      "8             9     21089 2021-06-26 11:14:53.541000+00:00     1     1\n",
      "10           11     21089 2021-06-26 11:14:58.645000+00:00     1     1\n",
      "...         ...       ...                              ...   ...   ...\n",
      "38778     38952     22514 2023-04-15 14:18:52.200000+00:00     3     2\n",
      "38779     38953     22514 2023-04-15 14:18:51.485000+00:00     3     2\n",
      "38780     38954     22514 2023-04-15 14:18:56.330000+00:00     3     2\n",
      "38781     38955     22514 2023-04-15 14:18:56.889000+00:00     3     2\n",
      "38782     38956     22514 2023-04-15 14:19:01.423000+00:00     3     2\n",
      "\n",
      "[26542 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Détection des phases dans les rounds\n",
    "data['phase'] = None\n",
    "\n",
    "# Parcourir tous les match_ids\n",
    "for match_id in match_ids:\n",
    "    # Sélectionner les lignes correspondant au match_id actuel\n",
    "    match_data = data[data['match_id'] == match_id].copy()\n",
    "\n",
    "    # Obtenir les rounds distincts pour le match_id actuel\n",
    "    rounds = match_data['round'].unique()\n",
    "\n",
    "    # Parcourir tous les rounds\n",
    "    for round_val in rounds:\n",
    "        \n",
    "        # Trier les valeurs par ordre chronologique dans la colonne \"date_create_app\"\n",
    "        round_data = match_data[match_data['round'] == round_val].copy()\n",
    "        round_data.sort_values(by='date_create_app', inplace=True)\n",
    "\n",
    "        # Conversion de la colonne \"date_create_app\" en valeurs numériques\n",
    "        round_data['timestamp'] = round_data['date_create_app'].apply(lambda x: pd.to_datetime(x).timestamp())\n",
    "\n",
    "        # Sélection des colonnes à utiliser pour le clustering\n",
    "        features = round_data[['timestamp']]\n",
    "\n",
    "        # Normalisation des caractéristiques\n",
    "        scaler = StandardScaler()\n",
    "        normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "        # Application de DBSCAN sans détection d'outliers\n",
    "        dbscan = DBSCAN(eps=0.5, min_samples=1)  # min_samples > 0 pour désactiver la détection d'outliers\n",
    "        labels = dbscan.fit_predict(normalized_features)\n",
    "\n",
    "        # Pour stocker les clusters détectés\n",
    "        labels += 1\n",
    "        round_data['cluster'] = labels\n",
    "\n",
    "        # Mise à jour de la colonne \"phase\"\n",
    "        data.loc[(data['match_id'] == match_id) & (data['round'] == round_val), 'phase'] = round_data['cluster'].values\n",
    "\n",
    "print(data[['score_id', 'match_id', 'date_create_app','round','phase']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a2bb0",
   "metadata": {},
   "source": [
    "## DTW\n",
    "\n",
    "### Détéction des échanges\n",
    "\n",
    "Ce code filtre les données en deux ensembles : \n",
    " - un ensemble sans pénalités\n",
    " - un ensemble avec pénalités. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "810b38f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes sans penalité : 20505\n",
      "Nombre de lignes de penalités : 6037\n"
     ]
    }
   ],
   "source": [
    "# Filtrage des lignes sans penalités\n",
    "dataset = data[(data['red_penalty'] == 0) & (data['blue_penalty'] == 0)]\n",
    "\n",
    "# Filtrage des lignes avec penalités\n",
    "filtered_data = data[(data['red_penalty'] != 0) | (data['blue_penalty'] != 0)]\n",
    "\n",
    "# Nombre de lignes dans chaque ensemble\n",
    "num_rows_dataset = len(dataset)\n",
    "num_rows_filtered_data = len(filtered_data)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Nombre de lignes sans penalité :\", num_rows_dataset)\n",
    "print(\"Nombre de lignes de penalités :\", num_rows_filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d72ac",
   "metadata": {},
   "source": [
    "Ce code effectue les opérations suivantes sur le jeu de données sans les pénalités :\n",
    "\n",
    "1. Il définit une fonction appelée `dtw_distance` qui calcule la distance DTW (Dynamic Time Warping) entre deux séquences de dates.\n",
    "\n",
    "2. Une liste appelée `final_data` est initialisée pour stocker les données finales.\n",
    "\n",
    "3. Le code parcourt chaque `match_id` unique dans le DataFrame `dataset`.\n",
    "\n",
    "4. Pour chaque `match_id`, il sélectionne  les données correspondantes.\n",
    "\n",
    "    5. Les rounds distincts pour le `match_id` spécifique sont obtenus.\n",
    "\n",
    "    6. Pour chaque round, les données du round actuel sont sélectionnées.\n",
    "\n",
    "        7. Les phases distinctes pour le round actuel sont obtenues.\n",
    "\n",
    "        8. Pour chaque phase, les données de la phase actuelle sont sélectionnées.\n",
    "\n",
    "            9. Les données de la phase sont triées par la colonne 'date_create_app' et la colonne 'date_create_app' est convertie en valeurs de temps en millisecondes.\n",
    "\n",
    "            10. La distance DTW est calculée pour chaque paire de lignes consécutives dans la phase en utilisant la fonction `dtw_distance`.\n",
    "            \n",
    "            11. L'écart-type de la distance DTW est calculé pour la phase actuelle.\n",
    "            \n",
    "        12. La détection des échanges est effectuée dans la phase en vérifiant : \n",
    "            13. Distance DTW : Si la distance DTW entre deux lignes consécutives dépasse l'écart-type de la distance DTW pour la phase actuelle, cela indique une variation significative entre ces deux lignes, ce qui peut être considéré comme un nouvel échange.\n",
    "            14. Identifiants de juge : Si le juge_id de la ligne actuelle est déjà présent dans les identifiants de juge uniques rencontrés précédemment dans l'échange, cela indique que le même juge a été sélectionné à nouveau pour cette ligne, ce qui peut être considéré comme un nouvel échange.   \n",
    "            \n",
    "            15. Nombre de lignes consécutives : Si le nombre de lignes consécutives atteint 3, cela indique que l'échange actuel est terminé et qu'un nouvel échange doit commencer.\n",
    "     \n",
    "        16. Les colonnes 'error' et 'judge_id_miss' sont ajoutées au DataFrame pour détecter les erreurs et les identifiants de juge manquants dans les échanges.\n",
    "\n",
    "       17. Les données de la phase sont ajoutées à la liste `final_data`.\n",
    "\n",
    "    18. Une fois toutes les phases traitées pour un `match_id`, le code continue avec le prochain `match_id` dans la boucle.\n",
    "\n",
    "19. Une fois toutes les données traitées, les données de toutes les phases sont concaténées dans le DataFrame `final_data`.\n",
    "\n",
    "\n",
    "Les données du DataFrame `filtered_data` (résultant du filtrage précédent) sont fusionnées avec `final_data` pour former `merged_data`. Les données fusionnées sont exportées dans un fichier CSV appelé \"resultat.csv\".\n",
    "\n",
    "En résumé, ce code effectue une série de traitements et de calculs sur les données pour détecter les échanges, les erreurs et les identifiants de juge manquants dans les phases des matchs. Les résultats sont ensuite exportés dans un fichier CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cecdd8a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier exporté.\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer la distance DTW entre deux séquences de dates\n",
    "def dtw_distance(sequence1, sequence2):\n",
    "    sequence1 = np.array(sequence1).reshape(-1, 1)\n",
    "    sequence2 = np.array(sequence2).reshape(-1, 1)\n",
    "    distance, _ = fastdtw(sequence1, sequence2, dist=euclidean)\n",
    "    return distance\n",
    "\n",
    "# Liste pour stocker les données finales\n",
    "final_data = []\n",
    "\n",
    "# Parcours de chaque match_id\n",
    "for match_id in dataset['match_id'].unique():\n",
    "    \n",
    "    # Sélection des données correspondant au match_id spécifique\n",
    "    match_data = dataset[dataset['match_id'] == match_id].copy()\n",
    "\n",
    "    # Rounds distincts pour le match_id spécifique\n",
    "    rounds = match_data['round'].unique()\n",
    "\n",
    "    # Parcours de chaque round\n",
    "    for round_val in rounds:\n",
    "        \n",
    "        # Sélection des données du round actuel\n",
    "        round_data = match_data[match_data['round'] == round_val].copy()\n",
    "\n",
    "        # Phases distinctes pour le round actuel\n",
    "        phases = round_data['phase'].unique()\n",
    "\n",
    "        # Parcours de chaque phase\n",
    "        for phase_val in phases:\n",
    "            \n",
    "            # Sélection des données de la phase actuelle\n",
    "            phase_data = round_data[round_data['phase'] == phase_val].copy()\n",
    "\n",
    "            # Tri des données par 'date_create_app'\n",
    "            phase_data.sort_values(by='date_create_app', inplace=True)\n",
    "\n",
    "            # Conversion de la colonne 'date_create_app' en valeurs de temps en millisecondes\n",
    "            phase_data['timestamp_ms'] = phase_data['date_create_app'].view('int64') // 10**6\n",
    "\n",
    "            # Calcul de la distance DTW pour chaque paire de lignes consécutives\n",
    "            phase_data['dtw_distance'] = 100 # Initilisation d'un seuil minimum pour facilité le calcul sinon retourne des infinis\n",
    "\n",
    "            for i in range(1, len(phase_data)):\n",
    "                previous_row = phase_data.iloc[i-1]\n",
    "                current_row = phase_data.iloc[i]\n",
    "                previous_sequence = [previous_row['timestamp_ms']]\n",
    "                current_sequence = [current_row['timestamp_ms']]\n",
    "\n",
    "                # Calcul de la distance DTW entre les deux séquences\n",
    "                distance = dtw_distance(previous_sequence, current_sequence)\n",
    "\n",
    "                # Mise à jour de la colonne \"dtw_distance\" avec la distance calculée\n",
    "                phase_data.at[current_row.name, 'dtw_distance'] = distance\n",
    "\n",
    "            # Calcul de l'écart-type de la distance DTW pour la phase actuelle\n",
    "            phase_std = phase_data['dtw_distance'].std()\n",
    "\n",
    "            # Détection des échanges\n",
    "            phase_data['echange'] = 1\n",
    "            echange_number = 1\n",
    "            line_count = 1\n",
    "            unique_judge_ids = set()\n",
    "\n",
    "            for i in range(len(phase_data)):\n",
    "                current_row = phase_data.iloc[i]\n",
    "                current_distance = current_row['dtw_distance']\n",
    "                current_judge_id = current_row['judge_id']\n",
    "                blue_point = current_row['blue_point']\n",
    "                red_point = current_row['red_point']\n",
    "\n",
    "                # Vérifier les conditions pour un nouvel échange\n",
    "                if (current_distance > phase_std # Distance supérieur à l'écart-type\n",
    "                    or current_judge_id in unique_judge_ids # Nouvel échange si le judge_id est déjà présent\n",
    "                    or line_count == 3 ): # Nombre de ligne pour un échange atteint\n",
    "                    \n",
    "                    echange_number += 1\n",
    "                    line_count = 1\n",
    "                    unique_judge_ids = set([current_judge_id])\n",
    "                else:\n",
    "                    line_count += 1\n",
    "                    unique_judge_ids.add(current_judge_id)\n",
    "\n",
    "                phase_data.at[current_row.name, 'echange'] = echange_number\n",
    "\n",
    "            # Ajout des colonnes \"error\" et \"judge_id_miss\"\n",
    "            phase_data['error'] = False\n",
    "            phase_data['judge_id_miss'] = 'ok' \n",
    "\n",
    "            # Parcours des échanges pour détecter les erreurs et les judge_id manquants\n",
    "            exchanges = phase_data['echange'].unique()\n",
    "\n",
    "            for exchange in exchanges:\n",
    "                exchange_data = phase_data[phase_data['echange'] == exchange].copy()\n",
    "\n",
    "                if len(exchange_data['judge_id'].unique()) == 3:\n",
    "                    unique_blue_points = exchange_data['blue_point'].unique()\n",
    "                    unique_red_points = exchange_data['red_point'].unique()\n",
    "\n",
    "                    if len(unique_blue_points) == 1 and len(unique_red_points) == 1:\n",
    "                        # Les trois judge_id ont attribué les mêmes points\n",
    "                        phase_data.loc[exchange_data.index, 'error'] = False\n",
    "                    else:\n",
    "                        # Au moins un judge_id a un jugement différent\n",
    "                        phase_data.loc[exchange_data[exchange_data['blue_point'] != unique_blue_points[0]].index, 'error'] = True\n",
    "                        phase_data.loc[exchange_data[exchange_data['red_point'] != unique_red_points[0]].index, 'error'] = True\n",
    "\n",
    "                if len(exchange_data['judge_id'].unique()) == 2:\n",
    "                    # Détecter le judge_id manquant dans l'échange\n",
    "                    missing_judge_id = set(phase_data['judge_id'].unique()) - set(exchange_data['judge_id'].unique())\n",
    "                    if missing_judge_id:\n",
    "                        phase_data.loc[exchange_data.index, 'judge_id_miss'] = missing_judge_id.pop()\n",
    "\n",
    "            # Conversion de la colonne 'date_create_app' au format heures, minutes, secondes et millisecondes pour un affichage simplifié\n",
    "            phase_data['date_create_app'] = pd.to_datetime(phase_data['date_create_app'])\n",
    "            phase_data['timestamp_ms'] = phase_data['date_create_app'].dt.strftime('%H:%M:%S.%f')\n",
    "           \n",
    "            # Ajout des données de la phase au tableau final\n",
    "            final_data.append(phase_data)\n",
    "\n",
    "final_data = pd.concat(final_data)\n",
    "\n",
    "merged_data = pd.concat([final_data, filtered_data])\n",
    "\n",
    "print(\"Fichier exporté.\")\n",
    "merged_data.to_csv('Resultat.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4dce0",
   "metadata": {},
   "source": [
    "Ce code compare les \"score_id\" entre deux fichiers CSV et ajoute les lignes correspondantes manquantes. Le DataFrame mis à jour est ensuite exporté dans un nouveau fichier CSV appelé \"resultat_final.csv\". Cette phase est pour récupérer toutes les lignes supprimées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cdb64a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\AppData\\Local\\Temp\\ipykernel_7284\\3747264973.py:1: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_resultat = pd.read_csv('resultat.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les lignes des score_id manquants ont été ajoutées dans resultat_final.csv.\n"
     ]
    }
   ],
   "source": [
    "df_resultat = pd.read_csv('resultat.csv')\n",
    "df_lcba_scores = pd.read_csv('LCBA_scores.csv')\n",
    "\n",
    "# Vérifier les \"score_id\" manquants dans resultat\n",
    "lcba_scores_ids = set(df_lcba_scores['score_id'])\n",
    "resultat_ids = set(df_resultat['score_id'])\n",
    "\n",
    "missing_ids = lcba_scores_ids - resultat_ids\n",
    "\n",
    "if len(missing_ids) > 0:\n",
    "    # Filtrer les lignes du DataFrame LCBA_scores contenant les \"score_id\" manquants\n",
    "    missing_rows = df_lcba_scores[df_lcba_scores['score_id'].isin(missing_ids)]\n",
    "\n",
    "    # Concaténer les lignes manquantes avec le DataFrame resultat\n",
    "    df_resultat = pd.concat([df_resultat, missing_rows], ignore_index=True)\n",
    "\n",
    "    # Exporter le DataFrame résultat avec les lignes manquantes dans un nouveau fichier CSV\n",
    "    df_resultat.to_csv('LCBA_resultat.csv', index=False)\n",
    "    print(\"Les lignes des score_id manquants ont été ajoutées dans resultat_final.csv.\")\n",
    "else:\n",
    "    print(\"Tous les score_id de LCBA_scores se trouvent déjà dans resultat.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f88f05",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Ce code caclul les éléments suivants :\n",
    "\n",
    "- `outliers_count = df_resultat.groupby('match_id')['outlier'].sum()` : Calcule le nombre d'outlier pour chaque \"match_id\".\n",
    "- `outliers_percentage = (outliers_count / total_rows_per_match_id) * 100` : Calcule le pourcentage d'outliers pour chaque \"match_id\".\n",
    "- `outliers_df = pd.DataFrame({'Match_id': outliers_count.index, 'Nombre d\\'anomalies': outliers_count, 'Pourcentage d\\'outliers': outliers_percentage})` : Crée un DataFrame appelé `outliers_df` pour stocker les résultats des outliers, contenant les colonnes \"Match_id\", \"Nombre d'anomalies\" et \"Pourcentage d'outliers\".\n",
    "\n",
    "\n",
    "- `errors_count = df_resultat.groupby('match_id')['error'].sum()` : Calcule le nombre d'erreur pour chaque \"match_id\".\n",
    "- `errors_percentage = (errors_count / total_rows_per_match_id) * 100` : Calcule le pourcentage d'erreurs pour chaque \"match_id\".\n",
    "- `errors_df = pd.DataFrame({'Match_id': errors_count.index, 'Nombre d\\'erreurs': errors_count, 'Pourcentage d\\'erreurs': errors_percentage})` : Crée un DataFrame appelé `errors_df` pour stocker les résultats des erreurs, contenant les colonnes \"Match_id\", \"Nombre d'erreurs\" et \"Pourcentage d'erreurs\".\n",
    "\n",
    "- `total_rows_per_match_id = df_resultat.groupby('match_id').size()` : Calcule le nombre total de lignes pour chaque \"match_id\" en utilisant la fonction `size()`.\n",
    "- `total_points = df_resultat.groupby(['match_id', 'judge_id'])[['red_point', 'blue_point']].sum()` : Calcule le nombre total de points attribués par chaque \"judge_id\" dans chaque \"match_id\".\n",
    "\n",
    "\n",
    "Ce code permet d'analyser les données du fichier \"resultat_final.csv\", de calculer des statistiques sur les outliers, les erreurs, les points attribués et les résultats d'échanges pour chaque \"match_id\", et d'exporter les résultats dans des fichiers Excel distincts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2c4546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\AppData\\Local\\Temp\\ipykernel_7284\\2420088018.py:2: DtypeWarning: Columns (38,40,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_resultat = pd.read_csv('LCBA_resultat.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportation des résultats dans les fichiers Excel terminée.\n"
     ]
    }
   ],
   "source": [
    "# Charger le fichier resultat_final.csv\n",
    "df_resultat = pd.read_csv('LCBA_resultat.csv')\n",
    "\n",
    "# Convertir les valeurs \"True\" dans la colonne \"outlier\" en 1 et les autres en 0\n",
    "df_resultat['outlier'] = df_resultat['outlier'].map({True: 1, False: 0})\n",
    "\n",
    "# Calculer le nombre de fois où il y a \"True\" dans la colonne \"outlier\" par \"match_id\"\n",
    "outliers_count = df_resultat.groupby('match_id')['outlier'].sum()\n",
    "\n",
    "# Calculer le nombre de fois où il y a \"True\" dans la colonne \"error\" par \"match_id\"\n",
    "errors_count = df_resultat.groupby('match_id')['error'].sum()\n",
    "\n",
    "# Calculer le nombre total de lignes par \"match_id\"\n",
    "total_rows_per_match_id = df_resultat.groupby('match_id').size()\n",
    "\n",
    "# Calculer le pourcentage d'outliers et d'erreurs par \"match_id\"\n",
    "outliers_percentage = (outliers_count / total_rows_per_match_id) * 100\n",
    "errors_percentage = (errors_count / total_rows_per_match_id) * 100\n",
    "\n",
    "# Calculer le nombre total de points attribués par chaque judge_id dans chaque match_id\n",
    "total_points = df_resultat.groupby(['match_id', 'judge_id'])[['red_point', 'blue_point']].sum()\n",
    "\n",
    "# Créer un DataFrame pour les résultats des outliers\n",
    "outliers_df = pd.DataFrame({'Match_id': outliers_count.index, 'Nombre d\\'anomalies': outliers_count, 'Pourcentage d\\'anomalie': outliers_percentage})\n",
    "\n",
    "# Créer un DataFrame pour les résultats des erreurs\n",
    "errors_df = pd.DataFrame({'Match_id': errors_count.index, 'Nombre d\\'erreurs': errors_count, 'Pourcentage d\\'erreurs': errors_percentage})\n",
    "\n",
    "# Exporter les résultats dans des fichiers Excel séparés\n",
    "outliers_df.to_excel('Anomalies.xlsx', index=False)\n",
    "errors_df.to_excel('Erreur.xlsx', index=False)\n",
    "total_points.to_excel('Total_points.xlsx')\n",
    "\n",
    "print(\"Exportation des résultats dans les fichiers Excel terminée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d6b76",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "810bca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'outliers : 120.0\n"
     ]
    }
   ],
   "source": [
    "total_outliers = df_resultat['outlier'].sum()\n",
    "print(\"Total d'outliers :\", total_outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c043c",
   "metadata": {},
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5676c370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'error dans le dataset : 740\n"
     ]
    }
   ],
   "source": [
    "total_errors = df_resultat['error'].sum()\n",
    "print(\"Total d'error dans le dataset :\", total_errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ebc6c",
   "metadata": {},
   "source": [
    "### Judge_id_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87ccf825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de juges manquants lors d'un échange :     judge_id  count\n",
      "0     114822  593.0\n",
      "1     114926  554.0\n",
      "2     114927  366.0\n",
      "3     114928  216.0\n",
      "4     113341  156.0\n",
      "..       ...    ...\n",
      "62    114980    5.0\n",
      "63    115278    4.0\n",
      "64    115277    3.0\n",
      "65    114872    2.0\n",
      "66    107723    1.0\n",
      "\n",
      "[67 rows x 2 columns]\n",
      "Total de count : 3830.0\n",
      "Exportation des résultats dans le fichier Excel terminée.\n"
     ]
    }
   ],
   "source": [
    "filtered_data = merged_data[merged_data['judge_id_miss'] != 'ok']\n",
    "\n",
    "judge_id_counts = filtered_data['judge_id_miss'].value_counts().reset_index()\n",
    "\n",
    "judge_id_counts.columns = ['judge_id', 'count']\n",
    "\n",
    "judge_id_counts['count'] = judge_id_counts['count'] / 2\n",
    "\n",
    "print(\"Total de juges manquants lors d'un échange :\", judge_id_counts)\n",
    "\n",
    "total_count = judge_id_counts['count'].sum()\n",
    "\n",
    "print(\"Total de count :\", total_count)\n",
    "\n",
    "judge_id_counts.to_excel('Judge_id_miss.xlsx', index=False)\n",
    "print(\"Exportation des résultats dans le fichier Excel terminée.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
